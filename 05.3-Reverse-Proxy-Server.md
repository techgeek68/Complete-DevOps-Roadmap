# Reverse Proxy Server:

----

A reverse proxy is a server that sits in front of one or more web servers, intercepting requests from clients before they reach the origin servers. It acts as a "front-door" for the servers, enhancing security by masking their identities, improving performance through caching and load balancing, and centralizing functions such as SSL encryption. 

**How it works**

Receives a request: 
- A client, which may be any web browser, requests a website. The request does not directly reach the origin server; instead, it first reaches the reverse proxy.
  
Forwards the request to the backend server:
- Now, the reverse proxy sends the request to the appropriate server, which may be a web server or a microservice.

Returns the response:
- The backend server processes the request and sends the response back to the reverse proxy, which then returns it to the original client.

<img width="2172" height="2780" alt="image" src="https://github.com/user-attachments/assets/ee3aa5ad-563a-45b8-9495-49dc555ba236" />


**Advantages**
Improved security:
- A reverse proxy conceals the IP addresses and properties of the backend servers, protecting them from possible attacks, such as those related to DDoS. It can also work like a security layer while scanning the requests and blocking malicious traffic.

Improved performance:
- The reverse proxy, by caching frequently accessed content, can serve it directly to clients, reducing the load on backend servers.

Load Balancing: 
- It can distribute the incoming client requests over multiple backend servers to avoid having any single server become a bottleneck and ensure high availability if one of them fails.

Centralized management: 
- Functions like SSL/TLS encryption/decryption, logging, and some security policies can be managed in one place at the level of the reverse proxy, easing maintenance and configuration tasks for the backend servers.

---
---

**1) Install and start Nginx**
```bash
# Debian/Ubuntu
sudo apt update && sudo apt install -y nginx

# RHEL/CentOS/Rocky
sudo dnf install -y nginx || sudo yum install -y nginx

sudo systemctl enable --now nginx
```
- Installs Nginx and ensures it starts on boot.

**2) Minimal reverse proxy**

  - `sudo vi /etc/nginx/conf.d/app.conf`
    
```nginx
server {
    listen 80;
    server_name example.com;

    location / {
        proxy_pass http://127.0.0.1:8080;
        proxy_set_header Host              $host;
        proxy_set_header X-Real-IP         $remote_addr;
        proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        proxy_connect_timeout 5s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;
    }
}
```
- Proxies all traffic to your backend and preserves client info via X-Forwarded-* headers.
- Conservative timeouts; adjust for your app’s latency.

**3) Validate and reload**
```bash
sudo nginx -t && sudo systemctl reload nginx
```
- Checks syntax and reloads without dropping connections.


---
---

**1) What Nginx as a Reverse Proxy Actually Does**
- Sits in front of your app(s) and forwards client requests.
- Gives you TLS termination, load balancing, caching, compression, rate limiting, IP controls, and consistent logs.
- Note: Nginx doesn’t minify CSS/JS or optimize images—that belongs in your build/CDN.


**2) Small but Important Setup Steps**
```bash
# Open firewall (if applicable)
sudo firewall-cmd --permanent --add-service=http
sudo firewall-cmd --permanent --add-service=https
sudo firewall-cmd --reload


# SELinux (if enforcing and proxying to remote backends)
sudo setsebool -P httpd_can_network_connect 1
```
- Let's traffic in and allow Nginx to talk to upstreams when SELinux is enforced.


**3) Good Defaults in nginx.conf**

  - `sudo vi /etc/nginx/nginx.conf`
    
```nginx
user  nginx;
worker_processes auto;
pid /var/run/nginx.pid;

events {
    worker_connections 4096;
    multi_accept on;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    # Rich logs with upstream timing
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct=$upstream_connect_time '
                    'uht=$upstream_header_time urt=$upstream_response_time';
    access_log /var/log/nginx/access.log main;
    error_log  /var/log/nginx/error.log warn;

    # Sensible performance defaults
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65s;
    types_hash_max_size 4096;
    server_tokens off;  # don’t leak version

    # Compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_comp_level 5;
    gzip_proxied any;
    gzip_types
        text/plain text/css application/json application/javascript
        application/xml text/xml image/svg+xml;

    # Shared cache for examples below
    proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=my_cache:128m
                     max_size=10g inactive=60m use_temp_path=off;

    # Reusable proxy headers (we’ll create this next)
    include /etc/nginx/snippets/proxy-headers.conf;

    include /etc/nginx/conf.d/*.conf;
}
```
- Sets solid defaults for logs, performance, and compression.
- Prepares a cache zone and includes a reusable headers snippet.


**4) Reusable Proxy Headers (avoid repetition)**

  - `sudo vi /etc/nginx/snippets/proxy-headers.conf`
    
```nginx
proxy_set_header Host              $host;
proxy_set_header X-Real-IP         $remote_addr;
proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;
proxy_set_header X-Forwarded-Proto $scheme;
proxy_set_header X-Forwarded-Host  $host;
proxy_set_header X-Forwarded-Port  $server_port;

# Keep connections to upstreams alive
proxy_http_version 1.1;
proxy_set_header Connection "";
```
- Standardized headers that many apps expect.
- Improves upstream performance with keepalive connections.

Optional: Brotli (if module exists)
```nginx
# Add inside http { ... }
brotli on;
brotli_comp_level 5;
brotli_types text/plain text/css application/javascript application/json application/xml+rss image/svg+xml;
```
- Smaller responses than gzip on many assets.


**5) Simple Reverse Proxy (clean baseline)**

  - `sudo vi /etc/nginx/conf.d/reverse-proxy.conf`
    
```nginx
server {
    listen 80;
    server_name example.com;

    access_log /var/log/nginx/reverse_access.log main;
    error_log  /var/log/nginx/reverse_error.log warn;

    location / {
        proxy_pass http://backend-server:8080;
        include /etc/nginx/snippets/proxy-headers.conf;

        proxy_connect_timeout 5s;
        proxy_send_timeout    30s;
        proxy_read_timeout    30s;

        proxy_buffering on;
        proxy_buffers 16 16k;
        proxy_buffer_size 32k;
    }
}
```
- A tidy, production-friendly starting point.
- Buffering helps with slow clients; adjust memory footprint as needed.


**6) Route to Multiple Apps (plus CORS done right)**
```nginx
# Upstreams with keepalive
upstream backend_app   { server 192.168.1.10:3000; server 192.168.1.11:3000; keepalive 64; }
upstream admin_panel   { server 192.168.1.12:4000; keepalive 32; }
upstream api_service   { server 192.168.1.13:5000; keepalive 64; }

server {
    listen 80;
    server_name mydomain.com;

    # Main app
    location / {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;
    }

    # Admin
    location /admin/ {
        proxy_pass http://admin_panel/;
        include /etc/nginx/snippets/proxy-headers.conf;
    }

    # Preflight (OPTIONS) for CORS
    location /api/ {
        if ($request_method = OPTIONS) {
            add_header Access-Control-Allow-Origin "*" always;
            add_header Access-Control-Allow-Methods "GET, POST, PUT, DELETE, OPTIONS" always;
            add_header Access-Control-Allow-Headers "Authorization, Content-Type" always;
            add_header Access-Control-Max-Age 86400 always;
            return 204;
        }
        proxy_pass http://api_service;
        include /etc/nginx/snippets/proxy-headers.conf;
        add_header Access-Control-Allow-Origin "*" always;
    }

    # Serve static files directly
    location /static/ {
        alias /var/www/static/;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```
- Routes different paths to different services.
- Handles CORS preflight cleanly; use specific origins for production if possible.
- alias avoids double /static in paths.


**7) HTTPS the Easy Way (Let’s Encrypt)**
```bash
# Debian/Ubuntu
sudo apt install -y certbot python3-certbot-nginx

# RHEL/Rocky/CentOS
sudo dnf install -y certbot python3-certbot-nginx || sudo yum install -y certbot python3-certbot-nginx

sudo certbot --nginx -d mydomain.com -d www.mydomain.com
sudo systemctl status certbot.timer  # confirm auto-renew
```
- Automatically gets and renews certs, updates Nginx config, and enables HTTP->HTTPS.

**Manual TLS (when you bring your own certs)**
```nginx
server {
    listen 443 ssl http2;
    server_name mydomain.com;

    ssl_certificate     /etc/nginx/ssl/mydomain.crt;
    ssl_certificate_key /etc/nginx/ssl/mydomain.key;

    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_stapling on;
    ssl_stapling_verify on;
    ssl_trusted_certificate /etc/nginx/ssl/mydomain.chain.pem;  # full chain for OCSP

    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    add_header X-Content-Type-Options nosniff;
    add_header X-Frame-Options DENY;
    add_header Content-Security-Policy "default-src 'self'; frame-ancestors 'none'" always;

    location / {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;
        proxy_set_header X-Forwarded-Proto https;
    }
}

server {
    listen 80;
    server_name mydomain.com;
    return 301 https://$host$request_uri;
}
```
- Solid TLS defaults with HTTP/2, HSTS, and OCSP stapling.
- Redirects all plain HTTP to HTTPS.


**8) Caching and Microcaching (safe defaults)**
```nginx
# my_cache defined in http { }

server {
    listen 80;
    server_name mydomain.com;

    # Static via upstream (cacheable forever)
    location ~* \.(?:jpg|jpeg|png|gif|ico|css|js|svg)$ {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;

        proxy_cache my_cache;
        proxy_cache_valid 200 302 1h;
        proxy_cache_valid 404 1m;
        proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;

        add_header X-Cache-Status $upstream_cache_status;

        # Only enable if your upstream wrongly sets cookies on assets
        # proxy_ignore_headers Set-Cookie;
    }

    # API microcache (GET/HEAD)
    location /api/ {
        proxy_pass http://api_service;
        include /etc/nginx/snippets/proxy-headers.conf;

        proxy_cache my_cache;
        proxy_cache_methods GET HEAD;
        proxy_cache_valid 200 302 5s;
        proxy_cache_key "$scheme$request_method$host$request_uri";
        add_header X-Cache-Status $upstream_cache_status;

        # Bypass cache when authenticated
        set $bypass_cache 0;
        if ($http_authorization ~* ".+") { set $bypass_cache 1; }
        if ($cookie_session     ~* ".+") { set $bypass_cache 1; }
        proxy_no_cache     $bypass_cache;
        proxy_cache_bypass $bypass_cache;
    }

    # Dynamic pages: no cache
    location / {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;
        proxy_no_cache 1;
        proxy_cache_bypass 1;
    }
}
```
- Caches safe content (static, cacheable GETs) and avoids caching authenticated requests.
- X-Cache-Status helps you see hits/misses in logs.


**9) Load Balancing + Failover (open-source friendly)**
```nginx
upstream backend_pool {
    least_conn;  # smoother under uneven loads
    server 192.168.1.10:8080 max_fails=3 fail_timeout=30s;
    server 192.168.1.11:8080 max_fails=3 fail_timeout=30s;
    server 192.168.1.12:8080 backup;
    keepalive 128;
}

server {
    listen 80;
    server_name mydomain.com;

    location / {
        proxy_pass http://backend_pool;
        include /etc/nginx/snippets/proxy-headers.conf;

        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
        proxy_next_upstream_tries 2;
        proxy_next_upstream_timeout 10s;
    }

    # Pass-through health endpoint
    location /health {
        proxy_pass http://backend_pool/health;
        include /etc/nginx/snippets/proxy-headers.conf;
        access_log off;
    }
}
```
- Uses passive health checks; NGINX Plus has active checks.
- least_conn is often better than round robin for APIs.


**10) WebSockets and SSE (don’t forget these bits)**
```nginx
server {
    listen 80;
    server_name mydomain.com;

    location / {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;
    }

    # WebSocket
    location /ws/ {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_read_timeout 3600s;
        proxy_send_timeout 3600s;
        proxy_buffering off;
    }

    # Server-Sent Events
    location /events/ {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;
        proxy_buffering off;
        proxy_read_timeout 3600s;
    }
}
```
- Upgrade/Connection headers are required for WebSockets.
- Disable buffering for real-time streams.


**11) Security: Rate Limits, Access Control, Hardening**
```nginx
# Define zones
limit_req_zone  $binary_remote_addr zone=api_rps:10m  rate=10r/s;
limit_req_zone  $binary_remote_addr zone=auth_rpm:10m rate=5r/m;
limit_conn_zone $binary_remote_addr zone=perip:10m;

server {
    listen 80;
    server_name mydomain.com;

    # API rate limits
    location /api/ {
        limit_req zone=api_rps burst=20 nodelay;
        limit_conn perip 20;
        proxy_pass http://api_service;
        include /etc/nginx/snippets/proxy-headers.conf;
    }

    # Stricter for auth
    location /api/auth/ {
        limit_req zone=auth_rpm burst=5 nodelay;
        limit_conn perip 5;
        proxy_pass http://api_service;
        include /etc/nginx/snippets/proxy-headers.conf;
    }

    # Restrict admin by IP
    location /admin/ {
        allow 192.168.1.0/24;
        allow 10.0.0.1;
        deny all;
        proxy_pass http://admin_panel;
        include /etc/nginx/snippets/proxy-headers.conf;
    }

    client_max_body_size 20m;  # adjust for uploads
    server_tokens off;

    # Block sensitive file paths
    location ~* \.(?:env|git|svn)(?:/|$) { return 403; }

    # Optional: block obvious scanners (use sparingly)
    if ($http_user_agent ~* (nikto|sqlmap|wget|curl)) { return 403; }
}
```
- Puts guardrails around abusive traffic and sensitive areas.
- Bumps upload limit for APIs that accept files.


**12) Performance: Buffers and Timeouts that Make Sense**
```nginx
server {
    listen 80;
    server_name mydomain.com;

    location / {
        proxy_pass http://backend_app;
        include /etc/nginx/snippets/proxy-headers.conf;

        proxy_buffering on;
        proxy_buffer_size 16k;
        proxy_buffers 16 16k;
        proxy_busy_buffers_size 64k;

        proxy_connect_timeout 5s;
        proxy_send_timeout 20s;
        proxy_read_timeout 20s;
    }
}
```
- Buffers help Nginx absorb bursts and slow clients.
- Timeouts protect you from hanging upstreams.


**13) Observability (know what’s happening)**
```nginx
# Local status (stub_status)
server {
    listen 127.0.0.1:8081;
    location /nginx_status {
        stub_status;
        access_log off;
        allow 127.0.0.1;
        deny all;
    }
}
```
- Get active connections and basic counters locally; scrape with a Prometheus exporter if needed.


**14) Operate and Validate**
```bash
# Validate and dump config
sudo nginx -t
sudo nginx -T

# Reload without dropping connections
sudo systemctl reload nginx

# Tail logs
sudo tail -f /var/log/nginx/access.log /var/log/nginx/error.log

# Sanity checks
curl -I http://mydomain.com
curl -kI https://mydomain.com

# Simple load test (if wrk installed)
wrk -t4 -c100 -d30s http://mydomain.com/
```
- Always test the config before reload.
- access.log + upstream timings are your best friend.


**15) Troubleshooting**
- 502 Bad Gateway:
    - Upstream down, DNS wrong, firewall/SELinux blocking. Test with curl from the Nginx host.
- 504 Gateway Timeout:
    - Upstream is slow; raise proxy_read_timeout or fix backend performance.
- 413 Request Entity Too Large:
    - Increase client_max_body_size.
- 499 Client Closed Request:
    - User cancelled or closed connection; often harmless.
- TLS issues:
    - Check full chain, SNI, and OCSP trusted chain; certbot renew logs help.


**16) Running Behind Another Proxy/CDN (real client IPs)**
```nginx
# Inside http { ... }
real_ip_header X-Forwarded-For;
set_real_ip_from 10.0.0.0/8;
set_real_ip_from 172.16.0.0/12;
set_real_ip_from 192.168.0.0/16;
# For Cloudflare, add their published IPs
# real_ip_recursive on;  # Use with care—trust chain matters
```
- Restores $remote_addr to the actual client when traffic comes via a trusted proxy/LB.


**17) A Practical Production Server (HTTP only example)**

  - `sudo vi /etc/nginx/conf.d/app.conf`
    
```nginx
upstream backend_servers {
    least_conn;
    server 192.168.1.10:8080 max_fails=3 fail_timeout=30s;
    server 192.168.1.11:8080 max_fails=3 fail_timeout=30s;
    server 192.168.1.12:8080 backup;
    keepalive 128;
}

server {
    listen 80;
    server_name mydomain.com www.mydomain.com;

    # Baseline security headers
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header Referrer-Policy "strict-origin-when-cross-origin";

    # App
    location / {
        proxy_pass http://backend_servers;
        include /etc/nginx/snippets/proxy-headers.conf;
        proxy_connect_timeout 5s;
        proxy_send_timeout    20s;
        proxy_read_timeout    20s;
    }

    # Static via upstream (cache hard)
    location ~* \.(?:js|css|png|jpg|jpeg|gif|ico|svg)$ {
        proxy_pass http://backend_servers;
        include /etc/nginx/snippets/proxy-headers.conf;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }

    # Health for external monitors
    location = /nginx-health {
        access_log off;
        add_header Content-Type text/plain;
        return 200 "healthy\n";
    }
}
```

- A clean, copy/paste-able starting point.
- Add HTTPS via certbot when you’re ready.
