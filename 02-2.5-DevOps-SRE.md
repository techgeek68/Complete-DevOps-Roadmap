**Introduction to SRE (Site Reliability Engineering)**

**What is SRE?**
SRE is a discipline that applies software engineering principles to IT operations to ensure system reliability. 

**Key practices include**:

- **Automation**: Replacing manual tasks (e.g., incident response) with code.

- **Service-Level Objectives (SLOs)**: Defining measurable reliability targets (e.g., 99.95% uptime).

- **Error Budgets**: Allowing a tolerance for failures before halting new feature releases.

**Real-Life Example** :

- **Google** pioneered SRE to manage services like Gmail and Search. By enforcing a 50% cap on "toil" (manual ops work), teams prioritize automation, reducing downtime and accelerating deployments.

- **Spotify** uses SRE principles to monitor its microservices, ensuring seamless user experiences even during peak traffic.

```

                                                          DevOps vs. SRE:

Aspect                     DevOps                                                               SRE

Focus on:                  End-to-end collaboration between Dev and Ops teams.                 Reliability and stability of production systems.


Key Practices:             CI/CD pipelines, cultural collaboration.                            SLOs, error budgets, and automation of toil.


Metrics:                   Deployment frequency, lead time.                                    Uptime, latency, error rates.


Philosophy:                "You build it, you run it".                                         "Operations is a software problem".

```


**Example:**

**Scenario: Content Delivery Network (CDN) Outage Response via SRE Practices**

**Incident Context:**

- A Content Delivery Network (CDN) provider rolled out a new Web Application Firewall (WAF) rule.
- The rule mistakenly caused half the edge servers to get stuck, resulting in widespread 502 Bad Gateway errors.

**Incident Timeline & Roles:**

1. **Detection & Alert:**
    → **13:42 UTC**
   
     - Monitoring alerts detect 502 rates exceeding 5% (Service Level Objective: SLO breach). PagerDuty page goes out to on-call SREs.
       
     - Monitoring tools detect error rates breaching the Error Budget (Error Budget) and page the on-call SRE.

3. **Assemble Incident Response Team(IRT):**
    → **13:50 UTC**
   
     - SRE Lead declares a Major Incident; assembles an Incident Response Team (IRT) with Networking, Security, and Ops SMEs.
       
     - The on-call SRE gathers network, security, and operations experts.

5. **Root-Cause Analysis:**
  → **14:05 UTC**

    - Hypothesis: external DDoS attack; initial mitigation attempts (rate-limiting) fail.
      
    - Logs and metrics show the new WAF rule entered a CPU spin loop on packet inspection.

7. **Rollback:**
    → **14:35 UTC**
   
     - Root cause identified: misconfigured WAF rule causing CPU spin loops on packet inspection.
       
     - The SRE team removes the faulty WAF rule globally; servers recover within 10 minutes.

9. **Blameless Postmortem**
    → **14:50 UTC**
     - Rollback WAF rule globally; service metrics return within SLO within 10 min.
       
     - Identify the missing canary rollout for firewall changes.
       
     - Action items:
       - Implement Canary Deployment (small-scale rollout first).
       - Add synthetic traffic tests against Web Application Firewall (WAF) in staging every 5 minutes.
       - Update the runbook with a “verify CPU load” step before global rollout
   

**Continuous Improvement:**

- **Infrastructure as Code (IaC):**
  
    All firewall configurations are managed in Git with pull-request reviews.

- **Automated Rollbacks**:
  
    CI/CD pipelines trigger automatic rollback if CPU or error metrics spike.


- **Knowledge Sharing**:

  Incident write-up circulated company-wide; SRE guild hosts a brown-bag session on lessons learned.


